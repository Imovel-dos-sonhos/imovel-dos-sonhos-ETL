{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da12853-13d6-4983-96ab-6331932ecd88",
   "metadata": {},
   "source": [
    "# Carregamento, tratamento e Análise dos dados presentes na camada Gold\n",
    "\n",
    "### Procedimentos\n",
    "\n",
    "Para que nossa camada <b>Gold</b> seja construida e carregada corratamente, precisamos primeiramente realizar alguns passos, sendo eles:\n",
    "\n",
    "- Configurar Spark e Acesso ao banco \n",
    "- Consultar os dados da camada Silver\n",
    "- Montar a estrutura Gold com os dados da silver\n",
    "- Inserir no banco\n",
    "- Tratar Movimentacoes\n",
    "\n",
    "### Configurar Spark e Acesso ao banco \n",
    "\n",
    "Primeira coisa a se fazer é configurar a ferramente que será utilizada para conectar ao banco de dados e interagir com o mesmo, sendo ela o PySpark. Para configurar o PySpark primeiramente temos que importar sua biblioteca e carregar nossas variaveis de ambiente para que ela possa acessar nosso banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a18501c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession iniciada com o driver PostgreSQL.\n",
      "Bibliotecas importadas e Variáveis configuradas\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, when, monotonically_increasing_id, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, DateType\n",
    "\n",
    "import glob\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "BASE_URL = \"jdbc:postgresql://\"\n",
    "HOST = \"imoveis.dos.sonhos.db\"\n",
    "PORT = \"5432\"\n",
    "USER = \"usrImoveisDosSonhos\"\n",
    "PASSWORD = \"S3nh@F0rte\"\n",
    "DATABASE = \"ImoveisDosSonhosDB\"\n",
    "\n",
    "JDBC_URL = f'{BASE_URL}{HOST}:{PORT}/{DATABASE}'\n",
    "TABELA = \"silver.imovelcaixa\"\n",
    "PROPRIEDADES = { \"user\": USER, \"password\": PASSWORD, \"driver\": \"org.postgresql.Driver\" }\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ImovelDosSonhosETL\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.5.0\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", 1000) \\\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"SparkSession iniciada com o driver PostgreSQL.\")\n",
    "\n",
    "print(\"Bibliotecas importadas e Variáveis configuradas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007555d2-fba4-48d7-a9b5-e438dbe36e5f",
   "metadata": {},
   "source": [
    "### Consultar os dados da camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "776e1f40-b58c-4f89-a2b4-6efdb493b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imoveis_silver = spark.read.jdbc(\n",
    "    url=JDBC_URL,\n",
    "    table=TABELA,\n",
    "    properties=PROPRIEDADES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f7b77-d4ec-4c03-a06e-44d1c9002b02",
   "metadata": {},
   "source": [
    "### Montar a estrutura Gold com os dados da silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d048d659-b7fa-427a-98a9-dbc11603f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DW Importado\n"
     ]
    }
   ],
   "source": [
    "## Localizacao\n",
    "df_localizacao_unique = imoveis_silver.select(\"UF\", \"Cidade\", \"Bairro\", \"Endereco\", \"NumeroImovel\").distinct()\n",
    "df_movimentacao_unique = imoveis_silver.select(\"ValorAvaliacao\", \"Desconto\", \"NumeroImovel\").distinct()\n",
    "df_fato_unique = imoveis_silver.select(\"NumeroImovel\", \"ValorAvaliacao\", \"Desconto\", \"UF\", \"Cidade\", \"Bairro\", \"Endereco\",).distinct();\n",
    "\n",
    "df_dim_localizacao = df_localizacao_unique \\\n",
    "    .withColumn(\"num_localizacao\", monotonically_increasing_id()) \\\n",
    "    .select(\n",
    "        col(\"NumeroImovel\").alias(\"num_imovel_Bk\"),\n",
    "        col(\"num_localizacao\"),\n",
    "        col(\"UF\").alias(\"sig_estado\"),\n",
    "        col(\"Cidade\").alias(\"nom_cidade\"),\n",
    "        col(\"Bairro\").alias(\"nom_bairro\"),\n",
    "        col(\"Endereco\").alias(\"nom_endereco\")\n",
    "    )\n",
    "\n",
    "df_dim_movimentacao = df_movimentacao_unique \\\n",
    "    .withColumn(\"num_movimentacao\", monotonically_increasing_id()) \\\n",
    "    .select(\n",
    "        col(\"NumeroImovel\").alias(\"num_imovel_Bk\"),\n",
    "        col(\"num_movimentacao\")\n",
    "    )\n",
    "\n",
    "df_dim_localizacao_existente = spark.read.jdbc(\n",
    "    url=JDBC_URL,\n",
    "    table=\"dw.dim_localizacao\",\n",
    "    properties=PROPRIEDADES\n",
    ")\n",
    "\n",
    "df_localizacao_cadastro = df_dim_localizacao.alias(\"candidata\").join(\n",
    "    df_dim_localizacao_existente.alias(\"existente\"),\n",
    "    on=[\n",
    "        col(\"candidata.sig_estado\") == col(\"existente.sig_estado\"),\n",
    "        col(\"candidata.nom_cidade\") == col(\"existente.nom_cidade\"),\n",
    "        col(\"candidata.nom_bairro\") == col(\"existente.nom_bairro\"),\n",
    "        col(\"candidata.nom_endereco\") == col(\"existente.nom_endereco\")\n",
    "    ],\n",
    "    how=\"left_anti\"\n",
    ").select(\n",
    "    col(\"candidata.num_imovel_Bk\"),\n",
    "    col(\"candidata.num_localizacao\"),\n",
    "    col(\"candidata.sig_estado\"),\n",
    "    col(\"candidata.nom_cidade\"),\n",
    "    col(\"candidata.nom_bairro\"),\n",
    "    col(\"candidata.nom_endereco\")\n",
    ")\n",
    "\n",
    "\n",
    "df_localizacao_cadastro.select(\n",
    "    col(\"num_localizacao\"),\n",
    "    col(\"sig_estado\"),\n",
    "    col(\"nom_cidade\"),\n",
    "    col(\"nom_bairro\"),\n",
    "    col(\"nom_endereco\")\n",
    ").write.jdbc(\n",
    "    url=JDBC_URL,\n",
    "    table=\"dw.dim_localizacao\", \n",
    "    mode=\"append\",\n",
    "    properties=PROPRIEDADES\n",
    ")\n",
    "\n",
    "df_dim_movimentacao.select(\n",
    "    col(\"num_movimentacao\"),\n",
    "    lit(\"CADASTRO\").alias(\"nom_tipo_movimentacao\"),\n",
    "    lit(\"SEM VALOR REGISTRADO\").alias(\"dsc_de\"),\n",
    "    lit(\"PREÇO BASE\").alias(\"dsc_para\")\n",
    ").write.jdbc(\n",
    "    url=JDBC_URL,\n",
    "    table=\"dw.dim_movimentacao\", \n",
    "    mode=\"append\",\n",
    "    properties=PROPRIEDADES\n",
    ")\n",
    "\n",
    "\n",
    "## Imovel\n",
    "df_imovel_unique = imoveis_silver.select(\n",
    "        \"NumeroImovel\",\n",
    "        \"Descricao\",\n",
    "        \"LinkDeAcesso\",\n",
    "        \"ModalidadeDeVenda\"\n",
    "    ).distinct()\n",
    "\n",
    "df_dim_imovel = df_imovel_unique \\\n",
    "    .select(\n",
    "        col(\"NumeroImovel\").alias(\"num_imovel\"),\n",
    "        col(\"LinkDeAcesso\").alias(\"url_acesso\"),\n",
    "        col(\"Descricao\").alias(\"dsc\"),\n",
    "        col(\"ModalidadeDeVenda\").alias(\"nom_modalidade_venda\")\n",
    "    )\n",
    "\n",
    "df_dim_imovel_existente = spark.read.jdbc(\n",
    "    url=JDBC_URL,\n",
    "    table=\"dw.dim_imovel\",\n",
    "    properties=PROPRIEDADES\n",
    ")\n",
    "\n",
    "\n",
    "df_imovel_cadastro = df_dim_imovel.alias(\"candidata\").join(\n",
    "    df_dim_imovel_existente.alias(\"existente\"),\n",
    "    on=[\n",
    "        col(\"candidata.num_imovel\") == col(\"existente.num_imovel\"),\n",
    "        col(\"candidata.url_acesso\") == col(\"existente.url_acesso\"),\n",
    "        col(\"candidata.dsc\") == col(\"existente.dsc\"),\n",
    "        col(\"candidata.nom_modalidade_venda\") == col(\"existente.nom_modalidade_venda\")\n",
    "    ],\n",
    "    how=\"left_anti\"\n",
    ").select(\n",
    "    col(\"candidata.num_imovel\"),\n",
    "    col(\"candidata.url_acesso\"),\n",
    "    col(\"candidata.dsc\"),\n",
    "    col(\"candidata.nom_modalidade_venda\")\n",
    ")\n",
    "\n",
    "df_imovel_cadastro.write.jdbc(\n",
    "    url=JDBC_URL,\n",
    "    table=\"dw.dim_imovel\", \n",
    "    mode=\"append\",\n",
    "    properties=PROPRIEDADES\n",
    ")\n",
    "print(\"DW Importado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e75e15e1-410b-4857-8bbd-e11a946e49e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw.Fato_VendaImovel importada.\n"
     ]
    }
   ],
   "source": [
    "df_fato_unico = imoveis_silver.select(\"ValorAvaliacao\", \"Desconto\", \"NumeroImovel\").distinct()\n",
    "\n",
    "df_fato = df_fato_unico.alias(\"silver\") \\\n",
    "    .withColumn(\"num_venda_imovel\", monotonically_increasing_id()) \\\n",
    "    .join(\n",
    "        df_dim_imovel.alias(\"imovel\"),\n",
    "        on=[col(\"silver.NumeroImovel\") == col(\"imovel.num_imovel\")],\n",
    "        how=\"inner\"\n",
    "    ) \\\n",
    "    .join(\n",
    "        df_dim_localizacao.alias(\"localizacao\"),\n",
    "        on=[col(\"silver.NumeroImovel\") == col(\"localizacao.num_imovel_BK\")],\n",
    "        how=\"inner\"\n",
    "    ) \\\n",
    "    .join(\n",
    "        df_dim_movimentacao.alias(\"movimentacao\"),\n",
    "        on=[col(\"silver.NumeroImovel\") == col(\"movimentacao.num_imovel_BK\")],\n",
    "        how=\"inner\"\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"num_venda_imovel\"),\n",
    "        col(\"imovel.num_imovel\").alias(\"FK_num_imovel\"),\n",
    "        col(\"movimentacao.num_movimentacao\").alias(\"FK_num_movimentacao\"),\n",
    "        col(\"localizacao.num_localizacao\").alias(\"FK_num_localizacao\"),\n",
    "        col(\"silver.ValorAvaliacao\").alias(\"val_avaliacao\"),\n",
    "        col(\"silver.Desconto\").alias(\"val_desconto\")\n",
    "    )\n",
    "\n",
    "\n",
    "df_fato.write.jdbc(\n",
    "        url=JDBC_URL,\n",
    "        table=\"dw.Fato_VendaImovel\", \n",
    "        mode=\"append\",\n",
    "        properties=PROPRIEDADES\n",
    "    )\n",
    "\n",
    "print(\"dw.Fato_VendaImovel importada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce6d65-7000-473f-84ed-ed0e6c652e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
